import os
from urllib.parse import urlparse, parse_qs
from collections import defaultdict
from tqdm import tqdm

# ğŸ¨ CLI Colors
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# ğŸ“¦ File extension mapping
extension_categories = {
    'js': ['.js'],
    'json': ['.json'],
    'php': ['.php'],
    'asp': ['.asp', '.aspx'],
    'jsp': ['.jsp'],
    'html': ['.html', '.htm'],
    'txt': ['.txt', '.log'],
    'xml': ['.xml'],
    'sql': ['.sql'],
    'config': ['.conf', '.config', '.ini', '.env'],
    'zip': ['.zip', '.tar', '.gz', '.rar', '.7z'],
    'bak': ['.bak', '.old', '.backup'],
    'css': ['.css'],
}

# ğŸ¯ Banner
def banner():
    print(f"""{Colors.OKCYAN}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ğŸ›¡ï¸  PassiveReconPro v1.0 ğŸ•µï¸â€â™‚ï¸          â•‘
â•‘     Advanced URL Intelligence & Analyzer      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{Colors.ENDC}""")

# ğŸ” Check if path is a file
def is_file_path(path):
    return '.' in path.split('/')[-1]

# ğŸ§ª Categorize by extension
def categorize_file(path):
    for category, extensions in extension_categories.items():
        if any(path.lower().endswith(ext) for ext in extensions):
            return category
    return 'others'

# ğŸ§  Main logic
def extract_dirs_files_params(urls):
    directories = set()
    files = set()
    parameters = set()
    domains = set()
    categorized_files = defaultdict(set)
    cms_hits = set()

    for url in tqdm(urls, desc=f"{Colors.OKBLUE}Analyzing URLs{Colors.ENDC}"):
        parsed = urlparse(url.strip())
        path = parsed.path
        domains.add(parsed.netloc)

        if not path or path == "/":
            continue

        # ğŸ¯ Extract directories
        parts = path.strip("/").split("/")
        for i in range(1, len(parts)):
            dir_path = "/" + "/".join(parts[:i]) + "/"
            directories.add(dir_path)

        # ğŸ“„ Extract files
        if is_file_path(path):
            files.add(path)
            category = categorize_file(path)
            categorized_files[category].add(path)
        else:
            directories.add(path if path.endswith("/") else path + "/")

        # ğŸ” CMS detection
        if "wp-admin" in path or "wp-content" in path:
            cms_hits.add("WordPress")
        if "public/index.php" in path:
            cms_hits.add("Laravel")

        # ğŸ§µ Extract GET parameters
        query = parsed.query
        if query:
            params = parse_qs(query)
            parameters.update(params.keys())

    return sorted(directories), sorted(files), sorted(parameters), sorted(domains), categorized_files, cms_hits

# ğŸ“ Read old data
def read_existing_set(file_path):
    if not os.path.exists(file_path):
        return set()
    with open(file_path, "r", encoding='utf-8', errors='ignore') as f:
        return set(line.strip() for line in f if line.strip())

# ğŸ“ Write updated list (no duplicates)
def write_updated_list(filepath, new_items):
    existing_items = read_existing_set(filepath)
    combined = sorted(existing_items.union(new_items))
    with open(filepath, "w") as f:
        f.write("\n".join(combined))

# ğŸ’¾ Save by extension
def save_all_wordlists(categorized_files):
    for category, paths in categorized_files.items():
        filepath = f"output/{category}.txt"
        write_updated_list(filepath, paths)
        print(f"{Colors.OKGREEN}[+] Saved {len(paths)} {category.upper()} paths to {filepath}{Colors.ENDC}")

# ğŸ“Š Print Summary
def print_summary(domains, directories, files, parameters, categorized_files, cms_hits):
    print(f"\n{Colors.HEADER}{Colors.BOLD}ğŸ“Š Summary Report:{Colors.ENDC}")
    print(f"{Colors.OKCYAN}ğŸŒ Domains found: {len(domains)}")
    for d in domains:
        print(f"   - {d}")

    print(f"{Colors.OKGREEN}ğŸ“ Total directories: {len(directories)}")
    print(f"{Colors.OKBLUE}ğŸ“„ Total files: {len(files)}")

    print(f"{Colors.WARNING}ğŸ” Parameters Extracted: {len(parameters)}")
    for p in parameters:
        print(f"   - {p}")

    print(f"{Colors.FAIL}ğŸ§© CMS Detection Hits: {', '.join(cms_hits) if cms_hits else 'None'}{Colors.ENDC}")

    print(f"{Colors.BOLD}\nğŸ“‚ File Extensions Breakdown:{Colors.ENDC}")
    for cat, items in categorized_files.items():
        print(f" - {cat.upper()}: {len(items)}")

# ğŸš€ Main function
def run_passive_recon(input_path):
    banner()

    if not os.path.exists(input_path):
        print(f"{Colors.FAIL}âŒ File not found: {input_path}{Colors.ENDC}")
        return

    with open(input_path, "r", encoding='utf-8', errors='ignore') as f:
        urls = [line.strip() for line in f if line.strip()]

    directories, files, parameters, domains, categorized_files, cms_hits = extract_dirs_files_params(urls)

    os.makedirs("output", exist_ok=True)
    write_updated_list("output/dirs.txt", directories)
    write_updated_list("output/files.txt", files)
    write_updated_list("output/params.txt", parameters)

    save_all_wordlists(categorized_files)
    print_summary(domains, directories, files, parameters, categorized_files, cms_hits)

    print(f"\n{Colors.OKGREEN}âœ… All results saved in 'output/' folder. Happy hacking! ğŸš€{Colors.ENDC}")

# ğŸ§ª Direct usage example
if __name__ == "__main__":
    # ğŸ“ Replace with your file or uncomment below to ask:
    # input_path = input("ğŸ“‚ Enter URL list file: ").strip()
    input_path = "urls.txt"
    run_passive_recon(input_path)
